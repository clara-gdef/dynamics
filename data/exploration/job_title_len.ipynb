{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "import ipdb\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import fasttext\n",
    "from nltk.tokenize import word_tokenize\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global CFG\n",
    "with open(\"../../config.yaml\", \"r\") as ymlfile:\n",
    "    CFG = yaml.load(ymlfile, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_file = \"bp_3jobs_desc_edu_skills_industry_date_company_FR\"\n",
    "splits = [\"TEST\", \"VALID\", \"TRAIN\"]\n",
    "MIN_JOB_COUNT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_file = os.path.join(CFG[\"gpudatadir\"], base_file + \"_TRAIN.json\")\n",
    "language_classifier = fasttext.load_model(os.path.join(CFG[\"modeldir\"], \"lid.176.bin\"))\n",
    "with open(current_file, 'r') as f:\n",
    "    num_lines = sum(1 for line in f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_seq_into_list(position):\n",
    "    number_regex = re.compile(r'\\d+(,\\d+)?')\n",
    "    new_tup = []\n",
    "    job = word_tokenize(position.lower())\n",
    "    for tok in job:\n",
    "        if re.match(number_regex, tok):\n",
    "            new_tup.append(\"NUM\")\n",
    "        else:\n",
    "            new_tup.append(tok.lower())\n",
    "    cleaned_tup = [item for item in new_tup if item != \"\"]\n",
    "    return cleaned_tup\n",
    "\n",
    "\n",
    "def handle_date(job):\n",
    "    if job[\"to\"] == \"Present\":\n",
    "        date_time_str = '2018-04-12'  # date of files creation\n",
    "        time = datetime.timestamp(datetime.strptime(date_time_str, '%Y-%m-%d'))\n",
    "    elif len(job[\"to\"].split(\" \")) == 2:\n",
    "        try:\n",
    "            time = datetime.timestamp(datetime.strptime(job[\"to\"], \"%B %Y\"))\n",
    "        except ValueError:\n",
    "            time = datetime.timestamp(datetime.strptime(job[\"to\"].split(\" \")[-1], \"%Y\"))\n",
    "    else:\n",
    "        try:\n",
    "            time = datetime.timestamp(datetime.strptime(job[\"to\"].split(\" \")[-1], \"%Y\"))\n",
    "        except ValueError:\n",
    "            date_time_str = '2018-04-13'  # date of files creation\n",
    "            time = datetime.timestamp(datetime.strptime(date_time_str, '%Y-%m-%d'))\n",
    "    tstmp = pd.Timestamp.fromtimestamp(time)\n",
    "    return round(datetime.timestamp(tstmp.round(\"D\").to_pydatetime()))\n",
    "\n",
    "def identify_language(job, ft_model):\n",
    "    jobs_str = \" \".join(job)\n",
    "    ft_model.predict([jobs_str])\n",
    "    return ft_model.predict([jobs_str])\n",
    "\n",
    "def build_new_person(person, language_classifier):\n",
    "    person_id = person[0]\n",
    "    industry = person[-1]\n",
    "    new_p = [person_id, industry]\n",
    "    jobs = []\n",
    "    for job in person[1]:\n",
    "        if 'company' in job.keys():\n",
    "            try:\n",
    "                end = handle_date(job)\n",
    "                tstmp = pd.Timestamp.fromtimestamp(job[\"from_ts\"])\n",
    "                start = round(datetime.timestamp(tstmp.round(\"D\").to_pydatetime()))\n",
    "                if (end > 0) and (start > 0):  # corresponds to the timestamp of 01/01/1970\n",
    "                    job = word_seq_into_list(job[\"position\"])\n",
    "                    predicted_lang = identify_language(job, language_classifier)\n",
    "                    if (predicted_lang[0][0][0] == \"__label__fr\" or predicted_lang[0][0][0] == \"__label__en\") and (predicted_lang[1][0][0] > .6):\n",
    "                        j = {'from': start,\n",
    "                             'to': end,\n",
    "                             'job': job}\n",
    "                        jobs.append(j)\n",
    "            except:\n",
    "                continue\n",
    "    if len(jobs) >= MIN_JOB_COUNT:\n",
    "        #trimmed_jobs = trim_jobs_to_max_len(jobs, args.max_len)\n",
    "        new_p.append(jobs)\n",
    "    return new_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487649/487649 [28:19<00:00, 286.88it/s]\n"
     ]
    }
   ],
   "source": [
    "titles_len = []\n",
    "with open(current_file, 'r') as f:\n",
    "    pbar = tqdm(f, total=num_lines)\n",
    "    dataset = []\n",
    "    for line in pbar:\n",
    "        current_person = json.loads(line)\n",
    "        jobs = current_person[1]\n",
    "        skills = current_person[2]\n",
    "        if len(jobs) >= MIN_JOB_COUNT and len(skills) > 0:\n",
    "            new_p = build_new_person(current_person, language_classifier)\n",
    "            if len(new_p) > 2 and len(new_p[-1]) >= MIN_JOB_COUNT:\n",
    "                dataset.append(new_p)\n",
    "                titles_len.append(len(new_p[-1]))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 372889/372889 [00:01<00:00, 360774.01it/s]\n"
     ]
    }
   ],
   "source": [
    "titles_len = []\n",
    "for person in tqdm(dataset):\n",
    "    for jobs in person[-1]:\n",
    "        titles_len.append(len(jobs[\"job\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(titles_len, 95) # .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_file = os.path.join(CFG[\"gpudatadir\"], f\"profiles_jobs_ind_title_TRAIN.pkl\")\n",
    "with open(ppl_file, 'rb') as fp:\n",
    "    toy_data = pkl.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[850898,\n",
       " 'Internet',\n",
       " [{'from': 1465596000, 'to': 1523484000, 'job': ['développeur', 'web']},\n",
       "  {'from': 1444514400, 'to': 1523484000, 'job': ['développeur', 'web']},\n",
       "  {'from': 1394492400, 'to': 1523484000, 'job': ['editor', 'chief']}]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[850901,\n",
       " 'Financial Services',\n",
       " [{'from': 1431295200,\n",
       "   'to': 1433109600,\n",
       "   'job': ['assistante',\n",
       "    'de',\n",
       "    'la',\n",
       "    'division',\n",
       "    'des',\n",
       "    'relations',\n",
       "    'avec',\n",
       "    'les',\n",
       "    'elus',\n",
       "    'et',\n",
       "    'les',\n",
       "    'acteurs',\n",
       "    'économiques']},\n",
       "  {'from': 1412978400,\n",
       "   'to': 1388530800,\n",
       "   'job': ['vendeuse', 'en', 'boulangerie']},\n",
       "  {'from': 1192053600,\n",
       "   'to': 1388530800,\n",
       "   'job': ['global', 'client', 'services', 'representative']}]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda10",
   "language": "python",
   "name": "cuda10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
